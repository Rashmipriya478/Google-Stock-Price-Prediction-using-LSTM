{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkqo4Vn7HYF9"
      },
      "outputs": [],
      "source": [
        "#Step 1 – Importing required libraries.\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM,Dropout,Dense"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 2 – Reading our training data.\n",
        "\n",
        "dataset_train = pd.read_csv('/content/Google_Stock_Price_Train.csv')\n",
        "training_set = dataset_train.iloc[:, 1:2].values\n",
        "\n",
        "sc = MinMaxScaler(feature_range = (0, 1))\n",
        "training_set_scaled = sc.fit_transform(training_set)\n",
        "\n",
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "for i in range(60, 1258):\n",
        "    X_train.append(training_set_scaled[i-60:i, 0])\n",
        "    y_train.append(training_set_scaled[i, 0])"
      ],
      "metadata": {
        "id": "spBT7uX2IQgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we are reading the input train data.\n",
        "We are just taking the first column here which is the ‘open’ column.\n",
        "Then we are initializing the MinMaxScaler to scale our data between 0 and 1.\n",
        "After that, we initialized two arrays X_train and y_train.\n",
        "The first entry in the X_train would be an array of the first 60 open stock prices and the first entry in the y_train will be the 61st value of open stock price.\n",
        "It means that we want our model to predict the 61st value of stock price when we provide it with the previous 60 values.\n",
        "In this way, we keep on building our X_train and y_train."
      ],
      "metadata": {
        "id": "Fs3oRjFTONNf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3 – Getting our training data in shape."
      ],
      "metadata": {
        "id": "mFt0pUo9OYS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = np.array(X_train), np.array(y_train)\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))"
      ],
      "metadata": {
        "id": "nJCDRrKGIQjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we are converting our lists to arrays.\n",
        "In the 2nd step, we are adding a dummy dimension in the end because Keras models require the data in this format only."
      ],
      "metadata": {
        "id": "2tPZU0XcOcFP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4 – Creating the Stock Price Prediction model."
      ],
      "metadata": {
        "id": "Wgc5bgUMOf4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regressor = Sequential()\n",
        "\n",
        "regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "regressor.add(LSTM(units = 50, return_sequences = True))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "regressor.add(LSTM(units = 50, return_sequences = True))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "regressor.add(LSTM(units = 50))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "regressor.add(Dense(units = 1))\n",
        "\n",
        "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
        "\n",
        "print(regressor.summary())"
      ],
      "metadata": {
        "id": "xBoc2SnNIQp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our Sequential model consists of 4 LSTM layers with 50 units each.\n",
        "After these LSTM layers, we have a Dense layer.\n",
        "We are using Adam optimizer here and the loss we are using is Mean Squared Error."
      ],
      "metadata": {
        "id": "kSdFJf16Oj3a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5 – Training the Stock Price Prediction model."
      ],
      "metadata": {
        "id": "V2WBqHTWOnA9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regressor.fit(X_train, y_train, epochs = 100, batch_size = 32)"
      ],
      "metadata": {
        "id": "ipgxCJdxIQwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training our model for 100 epochs.\n",
        "The batch size which we have taken is 32.\n",
        "You can also experiment with these values."
      ],
      "metadata": {
        "id": "75KzAepfOqz-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6 – Reading the test data."
      ],
      "metadata": {
        "id": "r-LaxGCFOuHy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_test = pd.read_csv('/content/Google_Stock_Price_Test.csv')\n",
        "real_stock_price = dataset_test.iloc[:, 1:2].values"
      ],
      "metadata": {
        "id": "0gs_no-4KcyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let’s read the test data to perform our predictions."
      ],
      "metadata": {
        "id": "uDaUnj0EOxFZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7 -Getting the Stock Price Predictions on test data."
      ],
      "metadata": {
        "id": "_pcTN9cDO1VT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the predicted stock price of 2017\n",
        "dataset_total = pd.concat((dataset_train['Open'], dataset_test['Open']), axis = 0)\n",
        "inputs = dataset_total[len(dataset_total) - len(dataset_test) - 60:].values\n",
        "inputs = inputs.reshape(-1,1)\n",
        "inputs = sc.transform(inputs)\n",
        "X_test = []\n",
        "for i in range(60, 80):\n",
        "    X_test.append(inputs[i-60:i, 0])\n",
        "X_test = np.array(X_test)\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
        "predicted_stock_price = regressor.predict(X_test)\n",
        "predicted_stock_price = sc.inverse_transform(predicted_stock_price)"
      ],
      "metadata": {
        "id": "xgbILmXEKirY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Concatenating the test ‘Open’ column with the train ‘Open’ column row-wise.\n",
        "The step we did above was just to take the last 60 values from the train data and also add that to the test data.\n",
        "Then we are reshaping it to have just one column and as many rows.\n",
        "Scaling it using MinMaxScaler.\n",
        "Then we are creating the test data as we did for the train data.\n",
        "And finally, we are making predictions."
      ],
      "metadata": {
        "id": "yGXGidWbO4is"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOTE – What we are doing above is we are first taking the last 60 open values from the train and making predictions from it for the 61st value. Then what we will do is we will drop the 0th open value and now our input array will be 1st open value to the 61st open value (60 values) and we will predict the 62nd open value and like this, we will keep on predicting the next value and take that for predicting next values."
      ],
      "metadata": {
        "id": "TNwOXsx3O98S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualising the results\n",
        "plt.plot(real_stock_price, color = 'red', label = 'Real Google Stock Price')\n",
        "plt.plot(predicted_stock_price, color = 'blue', label = 'Predicted Google Stock Price')\n",
        "plt.title('Google Stock Price Prediction')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Google Stock Price')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CoRhxcREKpa7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we are simply plotting our predictions in the blue curve.\n",
        "The red curve represents its true value, which means what it should be exactly.\n",
        "We can see that our model is not that perfect but still it is capable of catching the spikes (where the curve starts to go up)."
      ],
      "metadata": {
        "id": "l8rwjfWtPBG7"
      }
    }
  ]
}